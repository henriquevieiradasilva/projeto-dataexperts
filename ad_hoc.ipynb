{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35314ddb-408d-4c12-b408-0e5bd6fac2cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pergunta de negócio: Como evoluíram as vendas mensais por categoria entre 2022 e 2025? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a31b7d0a-0fbb-4bac-a435-1c6ba18536fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, col, desc, row_number, round\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Tabela fato_vendas \n",
    "fato_vendas = \"data_ex.gold.fato_vendas\"\n",
    "dim_categoria    = \"data_ex.gold.dim_categoria_produto\"\n",
    "\n",
    "\n",
    "# Seleção da categoria e de sua respectiva sk\n",
    "categoria_produto = (\n",
    "    spark.table(dim_categoria)\n",
    "         .select(\"categoria_nome\", \"sk_categoria\")\n",
    "         .distinct()\n",
    ")\n",
    "\n",
    "# Seleção de vendas totais por categoria em função de ano/mes\n",
    "vendas = (spark.table(fato_vendas)\n",
    "                    .groupBy(\"ano\", \"mes\", \"sk_categoria\")\n",
    "                    .agg(sum(\"valor_total\").alias(\"total_vendas\"))  \n",
    "                )\n",
    "\n",
    "vendas = (vendas.join(categoria_produto.select(\"sk_categoria\", \"categoria_nome\"), on=\"sk_categoria\").drop(\"sk_categoria\"))\n",
    "\n",
    "# Separacao por categoria\n",
    "for categoria in categoria_produto.select(\"categoria_nome\").collect():\n",
    "    \n",
    "    vendas_categoria = (\n",
    "        vendas\n",
    "            .filter(col(\"categoria_nome\") == categoria.categoria_nome)\n",
    "            .orderBy(\"ano\", \"mes\")\n",
    "            .select(\"ano\", \"mes\", \"total_vendas\")\n",
    "            .collect()\n",
    "    )\n",
    "    \n",
    "    if not vendas_categoria:\n",
    "        continue\n",
    "\n",
    "    x = [f\"{r.ano}-{str(r.mes).zfill(2)}\" for r in vendas_categoria]\n",
    "    y = [r.total_vendas for r in vendas_categoria]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(18, 4))\n",
    "    plt.plot(x, y, marker=\"o\")\n",
    "    plt.title(f\"Vendas - {categoria.categoria_nome}\")\n",
    "    plt.xlabel(\"Período (Ano-Mês)\")\n",
    "    plt.ylabel(\"Total de Vendas\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15ddd661-5456-49c5-a8f8-7653a165ca2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pergunta de negócio: Quais os top 10 produtos por valor_total e sua participação no total? \n",
    "* Consulta: ranking por valor_total com cálculo de participação (%) sobre o total geral.\n",
    "* Insight esperado: Insight: concentração de receita e dependência de poucos produtos.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6306fb4c-6a95-4df9-b80d-84533115ffb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, col, desc, row_number, round\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "fato_vendas = \"data_ex.gold.fato_vendas\"\n",
    "dim_categoria = \"data_ex.gold.dim_categoria_produto\"\n",
    "dim_produto = \"data_ex.gold.dim_produto\"\n",
    "\n",
    "# Tabelas\n",
    "produtos = spark.table(dim_produto).select(\"sk_produto\", \"produto_id\")\n",
    "categorias = spark.table(dim_categoria).select(\"sk_categoria\", \"categoria_nome\")\n",
    "\n",
    "vendas_categoria = spark.table(fato_vendas).groupBy(\"sk_categoria\").agg(sum(\"valor_total\").alias(\"vendas_categoria\"))\n",
    "vendas_produtos = spark.table(fato_vendas).groupBy(\"sk_produto\", \"sk_categoria\").agg(sum(\"valor_total\").alias(\"vendas_produto\"))\n",
    "\n",
    "vendas_totais = vendas_categoria.agg(sum(\"vendas_categoria\")).first()[0]\n",
    "\n",
    "# Join para saber o id dos produtos e o nome das categorias\n",
    "vendas_categoria = vendas_categoria.join(categorias.select(\"sk_categoria\", \"categoria_nome\"), on=\"sk_categoria\").drop(\"sk_categoria\")\n",
    "\n",
    "vendas_produtos = vendas_produtos.join(categorias.select(\"sk_categoria\", \"categoria_nome\"), on=\"sk_categoria\").drop(\"sk_categoria\")\n",
    "vendas_produtos = vendas_produtos.join(produtos.select(\"sk_produto\", \"produto_id\"), on=\"sk_produto\").drop(\"sk_produto\")\n",
    "\n",
    "\n",
    "# VENDAS POR PRODUTO (2022~2025)\n",
    "produtos_rank = vendas_produtos.withColumn(\"rank\", row_number().over(Window.orderBy(col(\"vendas_produto\").desc())))\n",
    "\n",
    "top_10 = produtos_rank.filter(col(\"rank\") <= 10)\n",
    "x = top_10.withColumn(\"participacao [%]\", round((col(\"vendas_produto\") * 100) / vendas_totais, 4) )\n",
    "\n",
    "print(\"VENDAS POR PRODUTOS\")\n",
    "print(\"Número de categorias: \", categorias.count())\n",
    "print(\"Número de produtos: \", produtos.count())\n",
    "\n",
    "y = x.agg(sum(\"participacao [%]\").alias(\"participacao [%]\")).first()[\"participacao [%]\"]\n",
    "print(f\"Top 10 produtos representam: {y}%\")\n",
    "\n",
    "x.show()\n",
    "\n",
    "# VENDAS POR CATEGORIA (2022~2025)\n",
    "categorias_rank = (\n",
    "    vendas_categoria\n",
    "        .withColumn(\"rank\", row_number().over(Window.orderBy(col(\"vendas_categoria\").desc())))\n",
    ")\n",
    "\n",
    "top_10 = categorias_rank.filter(col(\"rank\") <= 10)\n",
    "x = top_10.withColumn(\"participacao [%]\", round((col(\"vendas_categoria\") * 100) / vendas_totais, 4) )\n",
    "print(\"VENDAS POR CATEGORIA\")\n",
    "x.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de5d61f7-491c-4799-b117-7c795b12221b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pergunta de negócio: Quais localidades (UF/cidade) apresentam maior ticket médio?\n",
    "* Consulta: média de valor_total por pedido (ou por cliente) agrupada por UF/cidade.\n",
    "* Insight esperado: Insight: potenciais mercados premium e oportunides regionais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c61cf428-0d42-4846-8b8b-d2ad62478211",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, col, desc, row_number, round\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "dim_localidade = \"data_ex.gold.dim_localidade\"\n",
    "fato_vendas = \"data_ex.gold.fato_vendas\"\n",
    "\n",
    "localidades = spark.table(dim_localidade).select(\"cidade_venda\", \"estado_venda\", \"sk_localidade\")\n",
    "\n",
    "vendas_parciais = (spark.table(fato_vendas)\n",
    "                    .filter(col(\"sk_localidade\").isNotNull())\n",
    "                    .groupBy(\"sk_localidade\")\n",
    "                    .agg(sum(\"valor_total\").alias(\"total_vendas_localidade\"))  \n",
    "                  )\n",
    "\n",
    "vendas_parciais = vendas_parciais.join(localidades, on=\"sk_localidade\", how=\"inner\").drop(\"sk_localidade\")\n",
    "\n",
    "vendas_totais = vendas_parciais.agg(sum(\"total_vendas_localidade\").alias(\"vendas\")).first()[\"vendas\"]\n",
    "\n",
    "media_vendas = vendas_parciais\\\n",
    "                  .withColumn(\"media_vendas\", round(col(\"total_vendas_localidade\")/vendas_totais,6))\\\n",
    "                  .withColumn(\"participacao[%]\", round((col(\"total_vendas_localidade\")*100)/vendas_totais,6))\n",
    "\n",
    "maiores_tickets = (\n",
    "    media_vendas\n",
    "        .withColumn(\"rank\", row_number().over(Window.orderBy(col(\"media_vendas\").desc())))\n",
    ")\n",
    "\n",
    "maiores_tickets_localidade = maiores_tickets.filter(col(\"rank\") <= 20)\n",
    "\n",
    "#maiores_tickets_localidade.show()\n",
    "\n",
    "estados = media_vendas.groupBy(\"estado_venda\").agg(sum(\"participacao[%]\"))\n",
    "estados = estados.withColumn(\"participacao[%]\", round(col(\"sum(participacao[%])\"),6)).drop(\"sum(participacao[%])\")\n",
    "estados_tickets = estados.withColumn(\"rank\", row_number().over(Window.orderBy(col(\"participacao[%]\").desc())))\n",
    "display(estados_tickets)\n",
    "\n",
    "sudeste= (\n",
    "    estados_tickets\n",
    "    .filter(col(\"estado_venda\").isin([\"SP\", \"RJ\", \"MG\"]))\n",
    "    .agg(sum(col(\"participacao[%]\")))\n",
    ").collect()[0]\n",
    "\n",
    "sul = (\n",
    "    estados_tickets\n",
    "    .filter(col(\"estado_venda\").isin([\"PR\", \"SC\", \"RS\"]))\n",
    "    .agg(sum(col(\"participacao[%]\")))\n",
    ").collect()[0]\n",
    "\n",
    "centro_oeste = (\n",
    "    estados_tickets\n",
    "    .filter(col(\"estado_venda\").isin([\"MT\",\"GO\",\"MS\",\"DF\"]))\n",
    "    .agg(sum(col(\"participacao[%]\")))\n",
    ").collect()[0]\n",
    "\n",
    "norte = (\n",
    "    estados_tickets\n",
    "    .filter(col(\"estado_venda\").isin([\"AC\",\"AP\",\"AM\",\"PA\",\"RO\",\"RR\",\"TO\"]))\n",
    "    .agg(sum(col(\"participacao[%]\")))\n",
    ").collect()[0]\n",
    "\n",
    "nordeste = (\n",
    "    estados_tickets\n",
    "    .filter(col(\"estado_venda\").isin([\"CE\",\"MA\",\"PI\",\"RN\",\"PE\",\"PB\",\"AL\",\"SE\",\"BA\"]))\n",
    "    .agg(sum(col(\"participacao[%]\")))\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"Sudeste: {sudeste}\")\n",
    "print(f\"Sul: {sul}\")\n",
    "print(f\"Centro-Oeste: {centro_oeste}\")\n",
    "print(f\"Norte: {norte}\")\n",
    "print(f\"Nordeste: {nordeste}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21caa64c-babc-4c5f-a2b6-0cd4dcb0890d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pergunta de negócio: Como a quantidade média por transação varia por categoria e por ano?\n",
    "* Consulta: média de quantidade por categoria_id e por ano(data_id). \n",
    "* Insight esperado: Insight: mudanças de comportamento de compra (packs maiores/menores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68b53588-d888-48a5-82c6-925be4b6c2b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, col, round\n",
    "from pyspark.sql.window import Window\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fato_vendas = \"data_ex.gold.fato_vendas\"\n",
    "dim_categoria = \"data_ex.gold.dim_categoria_produto\"\n",
    "\n",
    "vendas = (\n",
    "    spark.table(fato_vendas)\n",
    "         .select(\"quantidade\", \"sk_categoria\", \"ano\")\n",
    ")\n",
    "\n",
    "categorias = (\n",
    "    spark.table(dim_categoria)\n",
    "         .select(\"sk_categoria\", \"categoria_nome\")\n",
    ")\n",
    "\n",
    "anos = [2022, 2023, 2024, 2025]\n",
    "\n",
    "# Join de vendas e categorias\n",
    "base_analitica = (\n",
    "    vendas\n",
    "        .filter(col(\"ano\").isin(anos))\n",
    "        .join(categorias, on=\"sk_categoria\", how=\"inner\")\n",
    ")\n",
    "\n",
    "# Calculando a média por categoria e ano\n",
    "media_quantidade_categoria_ano = (\n",
    "    base_analitica\n",
    "        .groupBy(\"categoria_nome\", \"ano\")\n",
    "        .agg(\n",
    "            round(avg(\"quantidade\"), 2)\n",
    "            .alias(\"media_quantidade_por_transacao\")\n",
    "        )\n",
    "        .orderBy(\"categoria_nome\", \"ano\")\n",
    ")\n",
    "\n",
    "# Transformando em tabela mais compreensível\n",
    "media_quantidade_pivot = (\n",
    "    media_quantidade_categoria_ano\n",
    "        .groupBy(\"categoria_nome\")\n",
    "        .pivot(\"ano\")\n",
    "        .agg(round(avg(\"media_quantidade_por_transacao\"), 2))\n",
    "        .orderBy(\"categoria_nome\")\n",
    ")\n",
    "\n",
    "# Visualização em tabelas\n",
    "display(media_quantidade_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4adad774-18ca-461a-97d1-e8d681db2a11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##  Pergunta de negócio: Quais clientes são responsáveis por 80% do faturamento (curva ABC)?\n",
    "* Consulta: cálculo de valor_total por cliente, ordenação e cumulativo até 80%. \n",
    "* Insight esperado: Insight: segmentação de clientes estratégicos para ações de retenção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec0d4afc-e09a-416a-955f-2bc9b7b3df50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, col, desc, row_number, round, when\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Importação das tabelas\n",
    "fato_vendas = \"data_ex.gold.fato_vendas\"\n",
    "dim_clientes = \"data_ex.gold.dim_cliente\"\n",
    "\n",
    "vendas = spark.table(fato_vendas).groupBy(\"sk_cliente\").agg(sum(\"valor_total\").alias(\"valor_total\"))\n",
    "clientes = spark.table(dim_clientes).select(\"sk_cliente\", \"nome_cliente\")\n",
    "vendas = vendas.join(clientes.select(\"sk_cliente\", \"nome_cliente\"), on=\"sk_cliente\", how=\"inner\").drop(\"sk_cliente\")\n",
    "\n",
    "# Calculos\n",
    "vendas_totais = vendas.agg(sum(\"valor_total\")).first()[0]\n",
    "\n",
    "vendas = vendas.withColumn(\"porcento\", (col(\"valor_total\")*100/vendas_totais))\n",
    "vendas = vendas.orderBy(col(\"porcento\").desc())\n",
    "\n",
    "window = Window.orderBy(desc(\"valor_total\")).rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "vendas = vendas.withColumn(\"percent_acumulado\", sum(\"porcento\").over(window))\n",
    "\n",
    "vendas = vendas.withColumn(\"abc\", when(col(\"percent_acumulado\")<= 80, \"A\")\\\n",
    "                                    .when((col(\"percent_acumulado\")>80) & (col(\"percent_acumulado\")<=95), \"B\")\\\n",
    "                                    .otherwise(\"C\"))\n",
    "\n",
    "vendas.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99faaf48-6bf9-4e7d-b766-b62a43369cc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.scatter(df['nome_cliente'], df['valor_total'], c=colors)\n",
    "#plt.xlabel('Cliente')\n",
    "#step = max(1, int(len(df) * 0.1))  # mostra a cada 10% dos dados\n",
    "#plt.xticks(df['nome_cliente'][::step], df['nome_cliente'][::step], rotation=45)\n",
    "plt.xticks([])\n",
    "plt.ylabel('Total Vendas')\n",
    "plt.title('Curva ABC - Scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f896556c-cd52-46f3-934b-c639a382c658",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Grafico de Pareto\n",
    "fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "df = vendas.toPandas()\n",
    "\n",
    "# Dominio, clientes \n",
    "ax1.bar(df['nome_cliente'], df['valor_total'], color='skyblue')\n",
    "\n",
    "\n",
    "# Imagem\n",
    "ax1.set_ylabel('Total Vendas', color='blue')\n",
    "\n",
    "# Linha do percentual acumulado\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(df['nome_cliente'], df['percent_acumulado'], color='red', marker='o', linewidth=1)\n",
    "ax2.set_ylabel('Percentual Acumulado (%)', color='red')\n",
    "\n",
    "#Limites ABC\n",
    "ax2.axhline(80, color='green', linestyle='--', label='A = 80%')\n",
    "ax2.axhline(95, color='orange', linestyle='--', label='B = 95%')\n",
    "\n",
    "# Infos\n",
    "ax2.legend(loc='upper left')\n",
    "plt.title('Curva ABC de Clientes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfb2f3ad-1cf8-402d-8c1f-d53cf017ab1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "colors = df['abc'].map({'A':'skyblue','B':'orange','C':'gray'})\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(df['nome_cliente'], df['valor_total'], color=colors)\n",
    "plt.xlabel('Cliente')\n",
    "plt.ylabel('Total Vendas')\n",
    "plt.title('Curva ABC - Barras coloridas por Classe')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d99c65d-467a-47d3-b639-abd1a627adce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df['nome_cliente'], df['percent_acumulado'], marker='o', color='red')\n",
    "plt.axhline(80, color='green', linestyle='--')\n",
    "plt.axhline(95, color='orange', linestyle='--')\n",
    "plt.xlabel('Cliente')\n",
    "plt.ylabel('Percentual Acumulado (%)')\n",
    "plt.title('Curva ABC - Percentual Acumulado')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ad_hoc",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
