{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28beab91-2da3-4a1e-9109-0fab7ed11023",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "***AVISO**: Esse Notebook foi feito com base na estrutura do Databricks Free Edition, que utiliza catálogos.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c29ca30a-af15-4715-96a7-2f16111e09eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **ETAPA 4 - PROCESSAMENTO PARA CAMADA GOLD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80024867-4e20-41ee-8d8e-c02167642565",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "Essa etapa será responsável por mover os dados para a camada gold, agrupando os dados e deixando pronto para uso.\n",
    "\n",
    "*`Complete as informações necessárias nos trechos que estão destacados em vermelho assim como esse, seguindo o padrão snake_case.`*\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22c44156-a1ae-42dc-a3a3-2fe4b4925076",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Parte 1 - **Importação das Bibliotecas Necessárias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e7c3e41-d88f-4866-b14e-ea897134430c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "ETAPA 4"
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import gc\n",
    "import urllib.request\n",
    "from os import listdir\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, StringType, TimestampType, LongType, DateType, TimestampType, BooleanType, DoubleType "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c70ade59-6355-403a-98f1-6745a5cdeb57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Parte 2 - **Otimizar a Sessão com configurações Personalizadas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7bc5207-23fc-47bd-b429-c0c28da66517",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Aqui o será configurado algumas propriedades para que o desempenho da sessão seja mais otimizado \n",
    "- Define tamanho fixo de partições para o shuffle para melhorar o paralelismo (usar ***número de partições = número de núclos de CPU * 2 ou 3*** para encontrar melhor cenário possível)\n",
    "- Define o tamanho máximo de partições para evitar muitos arquivos pequenos\n",
    "- Usa o codec Snappy para compressão rápida, otimizando tempo de leitura e escrita\n",
    "- Habilita otimizações adaptativas, ajustando o número de partições dinamicamente com base no tamanho dos dados\n",
    "- Habilita a extensão do Spark SQL para o Delta Lake, permitindo o uso de recursos avançados como ACID transactions, schema enforcement e time travel\n",
    "- Define o catálogo padrão do Spark como o catálogo Delta, garantindo que operações de leitura, escrita e gerenciamento de tabelas utilizem o engine do Delta Lake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b899d918-13a5-45b3-92d3-da404e5b729c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "ETAPA 4"
    }
   },
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"Carga Delta\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "        .config(\"spark.sql.files.maxPartitionBytes\", \"134217728\") \n",
    "        .config(\"spark.sql.parquet.compression.codec\", \"snappy\")\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "        .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b215062-6919-484b-9134-93fd9667b2f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Parte 3 - **Definindo Origens, Arquivos e Destinos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "413ffcba-c5a9-4781-b4e7-b02b570e490d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "`Complete as variáveis:`<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f111c89-d0e4-4a1e-a842-c0d4f6339b99",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "ETAPA 4 - Variáveis"
    }
   },
   "outputs": [],
   "source": [
    "nome_datalakehouse = \"dataexperts\"\n",
    "\n",
    "nome_camada_silver = \"silver\"\n",
    "nome_volume_silver= \"vendas\" \n",
    "\n",
    "nome_camada_gold = \"gold\"\n",
    "nome_volume_gold = \"vendas\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ce3867f-0131-4741-885f-29eadc3dbbc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O código a seguir armazena em variáveis os caminhos já prontos de origem e de destino dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8baa0fbb-3936-4065-863b-ed99eaef8bc9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "ETAPA 4"
    }
   },
   "outputs": [],
   "source": [
    "origem_dados = f\"/Volumes/{nome_datalakehouse}/{nome_camada_silver}/{nome_volume_silver}\"\n",
    "destino_dados = f\"/Volumes/{nome_datalakehouse}/{nome_camada_gold}/{nome_volume_gold}\"\n",
    "destino_tabelas = f\"{nome_datalakehouse}.{nome_camada_gold}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08589e1f-225b-40b1-974a-29809a90e1fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O código a seguir cria o volume de destino caso ele ainda não exista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32f0562e-3876-47c1-b4d6-6feaf0cb97dc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "ETAPA 4"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {nome_datalakehouse}.{nome_camada_gold}.{nome_volume_gold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e00a531-bf76-446e-ac4b-4004b402145f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Parte 4 - **Agrupando dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "346728f4-a03a-4b61-861b-3bb8c1cd2852",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O código a seguir faz a leitura dos arquivos da camada silver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dfe67ba-f89c-4729-a23f-e3d22824d14b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "ETAPA 4"
    }
   },
   "outputs": [],
   "source": [
    "def read(volume, file_name):\n",
    "    try:\n",
    "        df = spark.read\\\n",
    "            .format(\"delta\")\\\n",
    "            .load(f\"{origem_dados}/{file_name}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao tentar ler {file_name}: {e}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6584391-8ad5-498f-a869-0b9e69c39d6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O código a seguir faz salva as tabelas prontas na camada gold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ebff3d2-bab1-485f-821c-6c2220e781ab",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "ETAPA 4"
    }
   },
   "outputs": [],
   "source": [
    "def save_table(df, new_file_name):\n",
    "    try:\n",
    "        if \"fato\" in new_file_name:\n",
    "            df_data = spark.read.format(\"delta\").load(f\"{destino_dados}/dim_data\")\n",
    "            \n",
    "            df_fato = df\\\n",
    "                .join(broadcast(\n",
    "                    df_data.select(\"sk_data\", \"ano\", \"mes\")),\n",
    "                      \"sk_data\")\\\n",
    "            \n",
    "            df_fato\\\n",
    "                .write\\\n",
    "                .format(\"delta\")\\\n",
    "                .mode(\"overwrite\")\\\n",
    "                .partitionBy(\"ano\",\"mes\")\\\n",
    "                .saveAsTable(f\"{destino_tabelas}.{new_file_name}\")\n",
    "            \n",
    "            df_fato\\\n",
    "                .write\\\n",
    "                .format(\"delta\")\\\n",
    "                .mode(\"overwrite\")\\\n",
    "                .save(f\"{destino_dados}/{new_file_name}\")\n",
    "            \n",
    "            return df_fato\n",
    "        else:\n",
    "            df.write\\\n",
    "                .format(\"delta\")\\\n",
    "                .mode(\"overwrite\")\\\n",
    "                .saveAsTable(f\"{destino_tabelas}.{new_file_name}\")\n",
    "            df.write\\\n",
    "                .format(\"delta\")\\\n",
    "                .mode(\"overwrite\")\\\n",
    "                .save(f\"{destino_dados}/{new_file_name}\")\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro na função save(): {e}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b835a6a-d241-4b33-8c73-cae94db85e32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Parte 5 - **Utilizando as funções**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6cd6dda-65b4-4c9b-a4db-8bec11aa593f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "ETAPA 4"
    }
   },
   "outputs": [],
   "source": [
    "new_files_names = [\n",
    "    \"dim_categoria_produto\",\n",
    "    \"dim_cliente\",\n",
    "    \"dim_data\", \n",
    "    \"dim_localidade\",\n",
    "    \"dim_produto\",\n",
    "    \"fato_vendas\"\n",
    "] \n",
    "\n",
    "files = listdir(f\"{origem_dados}\")\n",
    "\n",
    "for i, (file, new_file_name) in enumerate(zip(files,new_files_names)): \n",
    "\n",
    "    df_read = read(nome_volume_gold, file)\n",
    "    df_read = save_table(df_read, new_file_name)\n",
    "\n",
    "    print(f\"Arquivo {file} processado com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05af758f-5c89-4426-bf26-00cb24a0fc32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Parte 6 - **Limpeza de Cache e Outros**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ced24514-ff45-42c0-a4e5-2b592fa75933",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O código a seguir libera memória de objetos não mais utilizados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "312fa31a-94aa-4800-8ae9-ef0ccb7109cf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "ETAPA 4"
    }
   },
   "outputs": [],
   "source": [
    "del files\n",
    "del new_files_names\n",
    "del volume\n",
    "del camada\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b7d0988-2bb3-47cc-ac8f-50a9a12ae41b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b502d971-d19f-44d2-b622-4fe18db73f6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f262bd2-2e6d-4979-b998-f62a70a5ea25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Código simples para mostrar se deu certo ou não essa etapa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fba10f2-0672-4627-bee3-91c6c3f19eb6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "ETAPA 4 - Resultados"
    }
   },
   "outputs": [],
   "source": [
    "# %skip\n",
    "new_files_names = [\n",
    "    \"dim_categoria_produto\",\n",
    "    \"dim_cliente\",\n",
    "    \"dim_data\", \n",
    "    \"dim_localidade\",\n",
    "    \"dim_produto\",\n",
    "    \"fato_vendas\"\n",
    "] \n",
    "\n",
    "def see_tables(new_file_names):\n",
    "    for file in new_files_names:\n",
    "        df = spark.read.format(\"delta\").load(f\"/Volumes/{nome_datalakehouse}/{nome_camada_gold}/{nome_volume_gold}/{file}\")\n",
    "        display(df)\n",
    "\n",
    "see_tables(new_files_names)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Etapa 4 - Processamento para Camada Gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
