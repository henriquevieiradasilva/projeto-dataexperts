{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d24b12e-3460-481b-b516-df476f060ce4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **ETAPA 2 - IMPORTAÇÃO DAS BASES DE DADOS**\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "Agora será feito a importação dos dados para a camada especificada do Data LakeHouse que já está pronta.\n",
    "\n",
    "*`Esse é um modelo modular, complete as informações necessárias nos trechos que estão destacados em vermelho assim como esse, seguindo o padrão snake_case.`*\n",
    "\n",
    "<br> \n",
    "\n",
    "***AVISO**: Esse Notebook foi feito com base na estrutura do Databricks Free Edition, que utiliza catálogos.*\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "### Parte 1 - **Importação das Bibliotecas Necessárias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46bd91bb-80cd-4c6d-afbf-1b92b957b134",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import pyspark \n",
    "import urllib\n",
    "import os\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "import importlib\n",
    "import funcoes_log\n",
    "importlib.reload(funcoes_log)\n",
    "from funcoes_log import create_pre_log, finalize_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a7107f0-f8f0-4554-b820-f26b8d9a8fbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "### Parte 2 - **Importação dos Arquivos para o Data Lakehouse**\n",
    "\n",
    "`Insira nas variáveis:` <br>\n",
    "`--> nome_datalakehouse --> nome do Data Lakehouse destino` <br>\n",
    "`--> nome_camada --> o nome da camada destino dos dados totalmente brutos` <br>\n",
    "`--> nome_volume_atual --> nome do volume onde ficaram os dados atualizados` <br>\n",
    "`--> nome_volume_historico --> nome do volume onde ficaram o histórico dos dados` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb457114-ee3f-4b63-b5dc-f654ce7ef169",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nome_datalakehouse = \"dataexperts\"\n",
    "nome_camada = \"landing_zone\"\n",
    "\n",
    "nome_volume_atual = \"vendas_atual\"\n",
    "nome_volume_historico = \"vendas_historico\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01b1381c-6700-48ec-9e73-6acfb47c7bad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O código a seguir cria os volumes se eles ainda não existirem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41e5b2b4-de82-4ddf-928f-565292da130d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE VOLUME IF NOT EXISTS {nome_datalakehouse}.{nome_camada}.{nome_volume_atual}\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE VOLUME IF NOT EXISTS {nome_datalakehouse}.{nome_camada}.{nome_volume_historico}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef66d7f4-e361-4584-8094-5fa20f716252",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "`Insira nos vetores todos os nomes dos arquivos que deseja importar e a origem deles, seguindo a mesma ordem:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4464dd7-5d61-4343-bbcc-79ac3e2c43e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "arquivos = [\n",
    "    \"categoria_produto.csv\",\n",
    "    \"cliente.csv\",\n",
    "    \"data.csv\",\n",
    "    \"localidade.csv\",\n",
    "    \"produto.csv\",\n",
    "    \"vendas_part1.csv\",\n",
    "    \"vendas_part2.csv\",\n",
    "    \"vendas_part3.csv\",\n",
    "    \"vendas_part4.csv\"\n",
    "]\n",
    "\n",
    "origem_arquivos = [\n",
    "    \"https://raw.githubusercontent.com/andrerosa1977/dataexperts2026/main/\",\n",
    "    \"https://raw.githubusercontent.com/andrerosa1977/dataexperts2026/main/\",\n",
    "    \"https://raw.githubusercontent.com/andrerosa1977/dataexperts2026/main/\",\n",
    "    \"https://raw.githubusercontent.com/andrerosa1977/dataexperts2026/main/\",\n",
    "    \"https://raw.githubusercontent.com/andrerosa1977/dataexperts2026/main/\",\n",
    "    \"https://raw.githubusercontent.com/andrerosa1977/dataexperts2026/main/\",\n",
    "    \"https://raw.githubusercontent.com/andrerosa1977/dataexperts2026/main/\",\n",
    "    \"https://raw.githubusercontent.com/andrerosa1977/dataexperts2026/main/\",\n",
    "    \"https://raw.githubusercontent.com/andrerosa1977/dataexperts2026/main/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7e12fac-e969-441e-ab70-bd32548dce58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O código a seguir verifica se o arquivo já existe no Data Lakehouse:\n",
    "- Se sim, apenas pula para o próximo download (se ainda exitir arquivos na fila em espera)\n",
    "- Se não, tenta baixar o arquivo da origem.\n",
    "Logo após, caso o download dê certo ou não, passa para a próximo download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd566461-ff7e-446c-8a3f-4d535831c7e2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 6"
    }
   },
   "outputs": [],
   "source": [
    "destino_atual = f\"/Volumes/{nome_datalakehouse}/{nome_camada}/{nome_volume_atual}/\"\n",
    "destino_historico = f\"/Volumes/{nome_datalakehouse}/{nome_camada}/{nome_volume_historico}/\"\n",
    "\n",
    "for arquivo, origem in zip(arquivos, origem_arquivos):\n",
    "\n",
    "    caminho_atual = os.path.join(destino_atual, arquivo)\n",
    "\n",
    "    TABELA_LOG = \"dataexperts.audit.logs\"\n",
    "\n",
    "    log = create_pre_log(\n",
    "        camada=\"landing_zone\",\n",
    "        tabela_log=TABELA_LOG,\n",
    "        job_nome=\"landing_zone_download_csv\",\n",
    "        acao=\"DOWNLOAD\",\n",
    "        nome_objeto=arquivo,\n",
    "        fonte=\"GITHUB\",\n",
    "        path_origem=origem + arquivo,\n",
    "        path_destino=caminho_atual\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(caminho_atual):\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            nome_historico = arquivo.replace(\".csv\", f\"_{timestamp}.csv\")\n",
    "            caminho_historico = os.path.join(destino_historico, nome_historico)\n",
    "            shutil.move(caminho_atual, caminho_historico)\n",
    "\n",
    "        urllib.request.urlretrieve(origem + arquivo, caminho_atual)\n",
    "        print(log.keys())\n",
    "\n",
    "        finalize_log(\n",
    "            spark,\n",
    "            log,\n",
    "            status=\"SUCCESS\",\n",
    "            registros_gravados=1\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        finalize_log(\n",
    "            spark,\n",
    "            log,\n",
    "            status=\"ERROR\",\n",
    "            mensagem_erro=str(e)\n",
    "        )\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65cb33d7-546b-4896-8585-9b8fae487ac1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE TABLE dataexperts.logs.bronze_historico;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a46b7258-71ad-41ca-91b6-5cd570738067",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Resultado Final**\n",
    "\n",
    "O código a seguir mostra todos os arquivos mais recentes salvos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4accc836-ecf5-49d4-a4d3-e2615dae5b32",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 12"
    }
   },
   "outputs": [],
   "source": [
    "# Código está comentado por ser apenas uma demonstração. Para visualizar o resultado, retire o identificador de comentário e execute novamente\n",
    "\n",
    "display(dbutils.fs.ls(destino_atual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a80f2005-b496-4ed2-98ca-0c38357d842e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "O código a seguir mostra o histórico de todas as versões dos arquivos salvos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d5af390-710c-4166-a0a3-0b06a03f823d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Código está comentado por ser apenas uma demonstração. Para visualizar o resultado, retire o identificador de comentário e execute novamente\n",
    "\n",
    "display(dbutils.fs.ls(destino_historico))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1084fdb7-5733-4a33-ab4b-b62fbe9ab502",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O código a seguir mostra um arquivo como exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e112f08-31f2-4287-80ce-d0d2cc3772fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Código está comentado por ser apenas uma demonstração. Para visualizar o resultado, retire o identificador de comentário e execute novamente\n",
    "\n",
    "arquivo_exemplo = f\"{destino_atual}/{arquivos[0]}\"\n",
    "\n",
    "dataframe_arquivo_exemplo = spark.read.csv(arquivo_exemplo, header=True)\n",
    "\n",
    "display(dataframe_arquivo_exemplo)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5108017277819344,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Etapa 2 - Importação das Bases de Dados",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
