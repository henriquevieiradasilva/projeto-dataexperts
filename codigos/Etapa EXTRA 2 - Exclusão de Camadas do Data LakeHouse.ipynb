{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3da96c0b-b984-46d4-a354-1f2674872c9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **ETAPA EXTRA 2 - EXCLUSÃO DE CAMADAS DO DATA LAKEHOUSE**\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "Esse é uma etapa extra não obrigatória para o caso de precisar excluir uma ou mais camadas do  Data LakeHouse que já existam.\n",
    "\n",
    "*`Esse é um modelo modular, complete as informações necessárias nos trechos que estão destacados em vermelho assim como esse, seguindo o padrão snake_case.`*\n",
    "\n",
    "<br> \n",
    "\n",
    "***AVISO**: Esse Notebook foi feito com base na estrutura do Databricks Free Edition, que utiliza catálogos.*\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "### Parte 1 - **Importação das Bibliotecas Necessárias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d7ee3d7-2eca-4c65-a4a0-38acdcb291b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Nesse caso não é necessário importar o pyspark, mas em um ambiente python padrão provalmente seria\n",
    "# import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12f78ea3-f80a-402a-ba9f-24805d2e44d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "### Parte 2 - **Exclusão das Camadas do Data Lakehouse**\n",
    "\n",
    "`Insira nas variáveis:` <br>\n",
    "`nome_datalakehouse --> Nome do lakehouse` <br>\n",
    "`nome_camadas --> Nomes das camadas que deseja excluir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea0b8e40-57a4-4fb2-8a35-cd96565a9cde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nome_datalakehouse = \"dataexperts\"\n",
    "nome_camadas = [\n",
    "  \"landing_zone\"\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69047a05-93e3-4764-b6d6-410bc50ccfb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Aqui serão criadas as **variáveis** para ajudar a **validar** se as camadas dentro do Data Lakehouse **já existem**, assim como o próprio Data LakeHouse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d316ef7-05fd-4456-8d1f-cc9ce27f6dd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datalakehouse_existe = True\n",
    "camadas_existem = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4118d8aa-c51e-4da6-96ac-be6df59f2123",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O código a seguir verifica se o Data Lakehouse existe ou não:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "617e9da5-5b62-4da6-9807-dda2b26d46ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataslakeshouses_existentes = spark.sql(\"SHOW CATALOGS;\")\n",
    "\n",
    "datalakehouse_existe = (\n",
    "    dataslakeshouses_existentes\n",
    "    .filter(dataslakeshouses_existentes.catalog == nome_datalakehouse)\n",
    "    .count() > 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "065a9c6c-8d5d-4a74-bc21-9b7aa5728c33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Aqui é o código para buscar todas os camadas existentes dentro do Data Lakehouse e armazenar o resultado dessa consulta em um Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3376760-5fc0-4817-9fb7-2e319cf8f0a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if datalakehouse_existe:\n",
    "    camadas_existentes = spark.sql(f\"SHOW SCHEMAS IN {nome_datalakehouse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9914a1e1-f106-4924-97da-55955e0ebfcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Por fim, o código a seguir exclui se o Data Lakehouse e a camada existir, caso contrário vai para a verificação da próxima camada a ser excluída:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2be7c5d6-f9b1-4060-9a55-0232c9f276e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if datalakehouse_existe:\n",
    "    for camada in nome_camadas:\n",
    "        camadas_existem[camada] = (\n",
    "            camadas_existentes\n",
    "            .filter(camadas_existentes.databaseName == camada)\n",
    "            .count() > 0\n",
    "        )\n",
    "\n",
    "        if camadas_existem[camada]:\n",
    "            spark.sql(f\"DROP SCHEMA {nome_datalakehouse}.{camada} CASCADE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba136b49-1850-4257-8f0d-19f24e8caed5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Resultado Final**\n",
    "\n",
    "Aqui é um log simples para mostrar se deu certo ou não a exclusão da camada do Data Lakehouse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfba7e10-213a-4aa4-8c68-44ea35f28b81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Código está comentado por ser apenas uma demonstração. Para visualizar o resultado, retire o identificador de comentário e execute novamente\n",
    "\n",
    "if not datalakehouse_existe:\n",
    "    print(f\"[LOG] O Data Lakehouse '{nome_datalakehouse}' não existe.\")\n",
    "else:\n",
    "    for camada, camada_existia in camadas_existem.items():\n",
    "        if camada_existia:\n",
    "            print(f\"[LOG] A camada '{camada}' existia e foi excluída com sucesso.\")\n",
    "        else:\n",
    "            print(f\"[LOG] A camada '{camada}' não existia e nenhuma ação foi executada.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Etapa EXTRA 2 - Exclusão de Camadas do Data LakeHouse",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
