{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6a31006-05ef-4fcd-a34f-5fe2328d0c07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Silver Layer\n",
    "\n",
    "Retirado do da branch da Mariana.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a5dda78-dd6e-4224-a7a7-572fe80e4506",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configuração do servidor para trabalho no Silver Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f32d9a95-bf8c-43cb-8715-fbd682faf98d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Configuração do ambiente Spark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4da75ca-ea7e-416b-b5c5-d5bf910581f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importação das bibliotecas necessárias\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import gc\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"Silver Layer - Transformations\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "        .config(\"spark.sql.files.maxPartitionBytes\", \"134217728\")  # 128MB\n",
    "        .config(\"spark.sql.parquet.compression.codec\", \"snappy\")\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "        .config(\"spark.databricks.delta.optimizeWrite.enabled\", \"true\")\n",
    "        .config(\"spark.databricks.delta.autoCompact.enabled\", \"true\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "# Conta quantos volumes já existem dentro do schema\n",
    "numero = spark.sql(\"show volumes in data_ex.lhdw\").count()\n",
    "# Armazena o nome do último volume salvo\n",
    "volume_salvo = f\"download{numero:03d}\"\n",
    "\n",
    "# Definição dos path bronze e silver\n",
    "bronze_path = f\"/Volumes/data_ex/bronze/{volume_salvo}\"\n",
    "silver_path = f\"/Volumes/data_ex/silver/{volume_salvo}\"\n",
    "\n",
    "spark.sql(f\"create volume if not exists data_ex.silver.{volume_salvo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a3e780a-a2ca-4953-988e-e5b6d7045a5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Controle de versionamento por volume**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe54f5d2-951b-410c-8a8c-c30277ec27de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema_name = \"data_ex.lhdw\"\n",
    "\n",
    "numero_volumes = spark.sql(f\"SHOW VOLUMES IN {schema_name}\").count()\n",
    "volume_atual = f\"download{numero_volumes:03d}\"\n",
    "\n",
    "bronze_path = f\"/Volumes/data_ex/bronze/{volume_atual}\"\n",
    "silver_path = f\"/Volumes/data_ex/silver/{volume_atual}\"\n",
    "\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS data_ex.silver.{volume_atual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6285213a-0675-484c-8c09-06b02e4b90a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Trabalhos no Silver Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54655ef9-f680-4406-8b20-c56d1723b5d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "edc17295-e1a9-4dbc-9b8f-777a1c0cc1b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "log_data{}\n",
    "\n",
    "def make_log_tabel(camada):\n",
    "    relacoes = {\n",
    "            \"bronze\" : \"bronze_log_carga\",\n",
    "            \"silver\" : \"silver_log_carga\",\n",
    "            \"gold\"   : \"gold_log_carga\"\n",
    "        }\n",
    "    n = 0\n",
    "    # Conta quantas tabelas existem\n",
    "    try:\n",
    "        n = spark.sql(\"show tables in data_ex.bronze\").count()\n",
    "    except:\n",
    "        print(\"ERRO ao ler a tabela de logs\")\n",
    "    # Cria a tabela se não existir \n",
    "    if n == 0:\n",
    "        try :\n",
    "            spark.sql(f\"\"\"create table if not exists data_ex.bronze.{relacoes[camada]} (\n",
    "                id_carga string,\n",
    "                id_job string,\n",
    "                nome_arquivo string,\n",
    "                fonte string,\n",
    "                camada string,\n",
    "                path_origem string,\n",
    "                path_destino string,\n",
    "                data_inicio timestamp,\n",
    "                data_fim timestamp,\n",
    "                duracao_ms string,\n",
    "                registros_lidos integer,\n",
    "                registros_gravados integer,\n",
    "                status string,\n",
    "                mensagem_erro string,\n",
    "                data_execusao date\n",
    "                ) using delta \"\"\")\n",
    "            return 1\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao criar a tabela de logs: {e}\")\n",
    "            return 0\n",
    "    # Erro, existe mais de uma tabela\n",
    "    elif n > 1:\n",
    "        print(f\"Erro na árvore de diretórios, exite mais de {n} tabelas de losgs na camada bronze\")\n",
    "        return 0\n",
    "    # A tabela ja existe\n",
    "    else:\n",
    "        print(\"Tabela de logs ja existes na camada bronze\")\n",
    "        return 1\n",
    "\n",
    "def generate_log(volume, camada ,camada_destino, file, new_name):\n",
    "    camada = camada.lower()\n",
    "    id_job = {\n",
    "        \"bronze\" : \"meta_bronze\",\n",
    "        \"silver\" : \"meta_silver\",\n",
    "        \"gold\"   : \"meta_silver\"\n",
    "    }\n",
    "  try:\n",
    "    global log_data\n",
    "    log_data.update({\n",
    "      \"id_carga\" : str(uuid.uuid4()),\n",
    "      \"id_job\"   : spark.sql(f\"select * from data_ex.metadados.{id_job[camada]}\").collect()[0][0],\n",
    "      \"nome_arquivo\" : new_name,\n",
    "      \"fonte\" : \"filesystem_local\",\n",
    "      \"camada\" : camada,\n",
    "      \"path_origem\" : f\"/Volumes/data_ex/{camada_origem}/{volume}/{file}\",\n",
    "      \"path_destino\" : f\"/Volumes/data_ex/{camada_destino}/{volume}/{new_name}\",\n",
    "      \"data_inicio\" : spark.range(1).select(current_timestamp()).collect()[0][0],\n",
    "      \"status\" : \"Running\",\n",
    "      \"data_execusao\" : spark.range(1).select(current_date()).collect()[0][0]\n",
    "    })\n",
    "    return 1\n",
    "  except Exception as e:\n",
    "    return 0\n",
    "\n",
    "def update_log():\n",
    "    try:\n",
    "        global log_data\n",
    "        log_data[\"status\"] = \"True\"   # Atualiza o status do log\n",
    "        data_fim = spark.range(1).select(current_timestamp()).collect()[0][0]\n",
    "        log_data[\"data_fim\"] = data_fim  \n",
    "        duracao_ms = (data_fim - log_data[7]).total_seconds() * 1000\n",
    "        log_data[\"duracao_ms\"] = duracao_ms\n",
    "        acao = storeLog(log_data)\n",
    "        if acao == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0 \n",
    "    except Exception as e:\n",
    "        print(f\"Erro na funcao gerarLog(): {e}\")\n",
    "\n",
    "def storeLog():\n",
    "    try:\n",
    "        global log_data\n",
    "        row = Row(\n",
    "            id_carga = log_data[\"id_carga\"],\n",
    "            id_job = log_data[\"id_job\"],\n",
    "            nome_arquivo = log_data[\"nome_arquivo\"],\n",
    "            fonte = log_data[\"fonte\"],\n",
    "            camada = log_data[\"camada\"],\n",
    "            path_origem = log_data[\"path_origem\"],\n",
    "            path_destino = log_data[\"path_destino\"],\n",
    "            data_inicio = log_data[\"data_inicio\"],\n",
    "            data_fim = log_data[\"data_fim\"],\n",
    "            duracao_ms = log_data[\"duracao_ms\"],\n",
    "            registros_lidos = log_data[\"registros_lidos\"],\n",
    "            registros_gravados = log_data[\"registros_gravados\"],\n",
    "            status = log_data[\"status\"],\n",
    "            mensagem_erro = log_data[\"mensagem_erro\"],\n",
    "            data_carga = log_data[\"data_carga\"]\n",
    "        )\n",
    "\n",
    "        df_log = spark.createDataFrame([row])\n",
    "        df_log.write.mode(\"append\").insertInto(\"data_ex.bronze.bronze_log_carga\")\n",
    "        return 1\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao gravar o log: {e}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d9ba315-3ed8-4de5-92bc-7dc3ae8c5da7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Leitura das tabelas bronze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4113b61-08cd-4d4a-9293-10a7c73d642b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_tables = {\n",
    "    \"dim_categoria\": \"bronze_dim_categoria_produto\",\n",
    "    \"dim_cliente\": \"bronze_dim_cliente\",        \n",
    "    \"dim_data\": \"bronze_dim_data\",\n",
    "    \"dim_localidade\": \"bronze_dim_localidade\",                \n",
    "    \"dim_produto\": \"bronze_dim_produto\",                    \n",
    "    \"fato_vendas\": \"bronze_fato_vendas\"                                 \n",
    "}\n",
    "\n",
    "bronze_dfs = {                            \n",
    "    nome: spark.read.format(\"delta\").load(f\"{bronze_path}/{tabela}\")\n",
    "    for nome, tabela in bronze_tables.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30c222b0-f2f8-4ed3-8851-32c366407124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Funções para a transformação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6403e03b-e7e2-41da-869a-92ff1023a7df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Função que substitui valores null por N/A\n",
    "def replace_null_string(df):\n",
    "    for coluna, tipo in df.dtypes:\n",
    "        if tipo == \"string\" and not coluna.endswith(\"_id\"):\n",
    "            df = df.withColumn(                                            \n",
    "                coluna,\n",
    "                when(col(coluna).isNull(), lit(\"N/A\")).otherwise(col(coluna))\n",
    "            )\n",
    "    return df\n",
    "\n",
    "# Função para adicionar SKs e FKs\n",
    "def add_surrogate_key(df, sk_name):\n",
    "    window = Window.orderBy(lit(1))\n",
    "    return df.withColumn(sk_name, row_number().over(window).cast(\"long\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3d8ab33-7c8b-4138-bee9-d744b0491437",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Transformando dimensões**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b388931-875f-4f1a-baf5-47b0875b4549",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def silver_categoria:\n",
    "    # Dimensão Categoria\n",
    "    silver_dim_categoria = (\n",
    "        bronze_dfs[\"dim_categoria\"]\n",
    "            .dropDuplicates([\"categoria_id\"])\n",
    "            .withColumn(\"categoria_nome\", upper(trim(col(\"categoria_nome\"))))\n",
    "    )\n",
    "    silver_dim_categoria = replace_null_string(silver_dim_categoria)\n",
    "    silver_dim_categoria = add_surrogate_key(silver_dim_categoria, \"sk_categoria\")\n",
    "\n",
    "def silver_cliente:\n",
    "    # Dimensão Cliente\n",
    "    silver_dim_cliente = (\n",
    "        bronze_dfs[\"dim_cliente\"]\n",
    "            .dropDuplicates([\"cliente_id\"])\n",
    "            .withColumn(\"nome_cliente\", initcap(trim(col(\"nome_cliente\"))))\n",
    "            .withColumn(\"estado_cliente\", upper(col(\"estado\"))) #renomear coluna\n",
    "            .withColumn(\"cidade_cliente\", initcap(col(\"cidade\"))) #renomear coluna\n",
    "            .drop(\"estado\", \"cidade\")\n",
    "    )\n",
    "    silver_dim_cliente = replace_null_string(silver_dim_cliente)\n",
    "    silver_dim_cliente = add_surrogate_key(silver_dim_cliente, \"sk_cliente\")\n",
    "\n",
    "def silver_data:\n",
    "    # Dimensão Data\n",
    "    silver_dim_data = (\n",
    "        bronze_dfs[\"dim_data\"]\n",
    "            .dropDuplicates([\"data_id\"])\n",
    "    )\n",
    "    silver_dim_data = replace_null_string(silver_dim_data)\n",
    "    silver_dim_data = add_surrogate_key(silver_dim_data, \"sk_data\")\n",
    "\n",
    "def silver_localidade\n",
    "# Dimensão Localidade\n",
    "    silver_dim_localidade = (\n",
    "        bronze_dfs[\"dim_localidade\"]\n",
    "            .dropDuplicates([\"localidade_id\"])\n",
    "            .withColumn(\"estado_venda\", upper(col(\"estado\"))) # renomear coluna\n",
    "            .withColumn(\"cidade_venda\", initcap(col(\"cidade\"))) # renomear coluna\n",
    "            .drop(\"estado\", \"cidade\")\n",
    "    )\n",
    "    silver_dim_localidade = replace_null_string(silver_dim_localidade)\n",
    "    silver_dim_localidade = add_surrogate_key(silver_dim_localidade, \"sk_localidade\")\n",
    "\n",
    "def silver_produto:\n",
    "# Dimensão Produto\n",
    "    silver_dim_produto = (\n",
    "        bronze_dfs[\"dim_produto\"]\n",
    "            .dropDuplicates([\"produto_id\"])\n",
    "            .drop(\"categoria_nome\") # remover categoria_nome\n",
    "            # .withColumn(\"categoria_nome\", upper(col(\"categoria_nome\")))\n",
    "    )\n",
    "    silver_dim_produto = replace_null_string(silver_dim_produto)\n",
    "    silver_dim_produto = add_surrogate_key(silver_dim_produto, \"sk_produto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "643d24e6-ca41-4df3-8758-0578c7da4d5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Transformando a tabela fato**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3042e56-862d-47b6-a0d2-500ccefe476c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def silver_fato_vendas:\n",
    "    silver_fato_vendas = (\n",
    "        bronze_dfs[\"fato_vendas\"]\n",
    "            .dropDuplicates([\"venda_id\"])\n",
    "            .filter(col(\"quantidade\") > 0)\n",
    "            # Categoria\n",
    "            .join(\n",
    "                silver_dim_categoria.select(\"categoria_id\", \"sk_categoria\"),\n",
    "                on=\"categoria_id\",\n",
    "                how=\"left\"\n",
    "            )\n",
    "            # Cliente\n",
    "            .join(\n",
    "                silver_dim_cliente.select(\"cliente_id\", \"sk_cliente\"),\n",
    "                on=\"cliente_id\",\n",
    "                how=\"left\"\n",
    "            )\n",
    "            # Produto\n",
    "            .join(\n",
    "                silver_dim_produto.select(\"produto_id\", \"sk_produto\"),\n",
    "                on=\"produto_id\",\n",
    "                how=\"left\"\n",
    "            )\n",
    "            # Data\n",
    "            .join(\n",
    "                silver_dim_data.select(\"data_id\", \"sk_data\"),\n",
    "                on=\"data_id\",\n",
    "                how=\"left\"\n",
    "            )\n",
    "            # Localidade\n",
    "            .join(\n",
    "                silver_dim_localidade.select(\"localidade_id\", \"sk_localidade\"),\n",
    "                on=\"localidade_id\",\n",
    "                how=\"left\"\n",
    "            )\n",
    "    )\n",
    "    # Removendo FKs null\n",
    "    silver_fato_vendas = silver_fato_vendas.filter(\n",
    "        col(\"sk_categoria\").isNotNull() & \n",
    "        col(\"sk_cliente\").isNotNull() &\n",
    "        col(\"sk_produto\").isNotNull() &\n",
    "        col(\"sk_data\").isNotNull() &\n",
    "        col(\"sk_localidade\").isNotNull()\n",
    "    )\n",
    "\n",
    "    # Removendo id's\n",
    "    silver_fato_vendas = silver_fato_vendas.drop(\n",
    "        \"categoria_id\",\n",
    "        \"cliente_id\",\n",
    "        \"produto_id\",\n",
    "        \"data_id\",\n",
    "        \"localidade_id\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2c2e577-7656-4439-91d3-da7343a302b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Salvar arquivos na camada Silver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c3d16d6-ad0a-4e23-ae2a-5a294cf9db05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Função de Save**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1ecd64c-cb1d-4841-a04a-b68d1ed4eb38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def save():\n",
    "    silver_tables = {\n",
    "        \"silver_dim_categoria_produto\": silver_dim_categoria,\n",
    "        \"silver_dim_cliente\": silver_dim_cliente,\n",
    "        \"silver_dim_data\": silver_dim_data,\n",
    "        \"silver_dim_localidade\": silver_dim_localidade,\n",
    "        \"silver_dim_produto\": silver_dim_produto,\n",
    "        \"silver_fato_vendas\": silver_fato_vendas\n",
    "    }\n",
    "\n",
    "    for nome_tabela, df in silver_tables.items():\n",
    "        (\n",
    "            df.write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .save(f\"{silver_path}/{nome_tabela}\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d87d0d5a-c18a-419b-8651-9903f702b31a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fca2bfc7-73a3-40cb-9b7c-af1c4d574926",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52da93c6-f30d-43df-9ff1-3b41f1cca63c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Limpar memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84325251-2dc9-460f-9b1a-8a3a311abe03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c72e00d-07ff-439f-afc8-e7353fb2f00f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Extra: printando tabelas transformadas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c0c2d64-c167-4b29-a2b3-39cc8955d179",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "silver_dim_categoria_produto = spark.read.format(\"delta\").load(\"/Volumes/data_ex/silver/download001/silver_dim_categoria_produto\")\n",
    "display(silver_dim_categoria_produto)\n",
    "\n",
    "silver_dim_cliente = spark.read.format(\"delta\").load(\"/Volumes/data_ex/silver/download001/silver_dim_cliente\")\n",
    "display(silver_dim_cliente)\n",
    "\n",
    "silver_dim_data = spark.read.format(\"delta\").load(\"/Volumes/data_ex/silver/download001/silver_dim_data\")\n",
    "display(silver_dim_data)\n",
    "\n",
    "silver_dim_localidade = spark.read.format(\"delta\").load(\"/Volumes/data_ex/silver/download001/silver_dim_localidade\")\n",
    "display(silver_dim_localidade)\n",
    "\n",
    "silver_dim_produto = spark.read.format(\"delta\").load(\"/Volumes/data_ex/silver/download001/silver_dim_produto\")\n",
    "display(silver_dim_produto)\n",
    "\n",
    "silver_fato_vendas = spark.read.format(\"delta\").load(\"/Volumes/data_ex/silver/download001/silver_fato_vendas\")\n",
    "display(silver_fato_vendas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f93e716e-486e-474a-9cf9-abdbd11ba4e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_fato_vendas = spark.read.format(\"delta\").load(\"/Volumes/data_ex/silver/download001/silver_fato_vendas\")\n",
    "display(silver_fato_vendas)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
